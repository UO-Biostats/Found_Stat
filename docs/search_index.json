[
["index.html", "Foundational Statistics - Bi 610 - Spring 2020 Chapter 1 Course Overview", " Foundational Statistics - Bi 610 - Spring 2020 Clayton M. Small and William A. Cresko 2020-04-09 Chapter 1 Course Overview This is the complete set of course materials for the Foundational Statistics Course at the University of Oregon for the Spring of 2020. It is written in Markdown so that it can be easily updated. In this book you will find nearly all the information you will need to complete the course. "],
["introduction-to-the-course.html", "Chapter 2 Introduction to the course 2.1 Instructors 2.2 Course Information 2.3 Software 2.4 Inclusion and Accessibility", " Chapter 2 Introduction to the course This is the complete set of course materials for the Foundational Statistics Course at the University of Oregon for the Spring of 2020. It is written in Markdown so that it can be easily updated. In this book you will find nearly all the information you will need to complete the course. 2.1 Instructors Dr. Clay Small, csmall@uoregon.edu Dr. Bill Cresko, wcresko@uoregon.edu 2.2 Course Information Virtual Office Hours: T-R 12 to 1:30 (Zoom) 2.3 Software Latest version of R Latest version of RStudio 2.4 Inclusion and Accessibility Please tell us your preferred pronouns and/or name, especially if it differs from the class roster. We take seriously our responsibility to create inclusive learning environments. Please notify us if there are aspects of the instruction or design of this course that result in barriers to your participation! You are also encouraged to contact the Accessible Education Center in 164 Oregon Hall at 541-346-1155 or uoaec@uoregon.edu. We are committed to making this course an inclusive and respectful learning space. Being respectful includes using preferred pronouns for your classmates. Your classmates come from a diverse set of backgrounds and experiences; please avoid assumptions or stereotypes, and aim for inclusivity. Let us know if there are classroom dynamics that impede your (or someone else’s) full engagement. Because of the COVID-19 pandemic, this course is being delivered entirely remotely. We realized that this situation makes it difficult for some students to interact with the material, for a variety of reasons. We are committed to flexibility during this stressful time and emphasize that we will work with students to overcome difficult barriers as they arise. Please see this page for more information on campus resources, academic integrity, discrimination, and harassment (and reporting of it). "],
["course-schedule.html", "Chapter 3 Course Schedule 3.1 Weeks 1-2 3.2 Week 3 3.3 Week 4 3.4 Week 5 3.5 Week 6 3.6 Week 7 3.7 Week 8 3.8 Week 9 3.9 Week 10", " Chapter 3 Course Schedule 3.1 Weeks 1-2 Data organization and management best practices, reproducibility, etc. Basic programming fundamentals for data curation The Unix environment and fundamental commands Formatting and manipulating tabular text files from the terminal Introduction to R and Rstudio Installation/Updates R object types and assignment Practice with R objects vectors, matrices, data frames, etc. Applying core programming fundamentals in R vectorized operations replicate, apply family, ifelse, for loops, etc. 3.2 Week 3 Plotting/visualizing data as a means of exploration Different plot types Scale, transformations, etc. Fundamentals of plotting in base R par using palettes, points, sizes, etc. to convey information axes and labels R markdown 3.3 Week 4 Population parameters, samples, and sampling distributions Central Limit Theorem and the normal dist. Mean and st. dev. Probability and probability distributions Calculating summary statistics Other common summary statistics (quantiles, etc.) 3.4 Week 5 Parameter estimation Simulating data sets with known parameters Revisit probability distributions Uncertainty in estimation Parametric and nonparametric approaches to uncertainty 3.5 Week 6 Experimental design lexicon considering sources of variance types of variables (categorical, ordinal, rational) confounding variables Frequentist hypothesis testing error types p-values degrees of freedom statistical power multiple testing problem 3.6 Week 7 Comparing means between groups Student’s t-test Bootstrapping and randomization to compare means 3.7 Week 8 Relationships between quantitative variables correlation and covariance Simple linear regression residuals and least squares fitting linear regression models 3.8 Week 9 Analysis of variance Table components and test statistics General linear models in R Model formulae Interpretation of summary output More complex ANOVA frameworks Nested models Factorial models 3.9 Week 10 Frequency-based statistical tests Chi-squared tests Contingency tables and tests of independence Brief introduction to generalized linear models (time permitting) logistic regression "],
["background-material-for-the-course.html", "Chapter 4 Background material for the course 4.1 Description of the course 4.2 Course goals: 4.3 Introduction to R and RStudio", " Chapter 4 Background material for the course 4.1 Description of the course This course in an introduction to data management, data visualization, and statistical inference. It is intended for early-stage graduate students with no background in statistics. No prior coursework (undergraduate or graduate) in statistics or programming is assumed. The primary objective of the course is to get students up to speed with respect to organization, manipulation, visualization, and analysis of data, using the R statistical language. The emphasis on application is strong, with the goal of enabling students (after the course) to analyze their own data sets with confidence using reasonable approaches, and, when faced with more difficult analysis problems, to be able to communicate their inference objectives clearly to expert analysts. Students will learn to organize and analyze data sets in the form of RStudio projects, using R Markdown files to reproducibly capture and render code, visualizations, and analyses. In-class exercises will be delivered in the form of pre-formatted R Notebooks, which can be interactively executed by students without having to write all code from scratch. The course is designed to acquaint students primarily with univariate (single response variable) analysis. Multivariate analysis will be covered in the Advanced Biostatics 2-course series offered during the Fall and Winter terms. Examples and assignments in class will include data sets primarily from the biological sciences, including studies of morphological and molecular traits, behaviors, ecological questions, and clinical studies. For specific statistical topics covered in class, please see the course goals and tentative schedule below. 4.2 Course goals: Properly organize and format primary data and metadata files for analysis Learn programming fundamentals of the R statistical language, including objects, functions, iteration, and simulation. Make publication-quality data visualizations, including scatterplots, boxplots, frequency distributions, mosaic plots, etc. Understand Type I and Type II statistical error, including p-values and power analysis. Understand ordinary least-squares regression and linear models in general Learn the fundamentals of strong experimental design Learn to apply general linear models to basic univariate analysis problems, including Analysis of Variance (ANOVA) Learn nonparametric approaches to parameter estimate and statistical inference, including resampling (bootstrapping), permutation, and rank- based analysis. Understand how to analyze binary response variables and frequency-based (e.g. contingency table) data sets. 4.3 Introduction to R and RStudio R is a core computational platform for statistical analysis. It was developed a number of years ago to create an open source envirnment for advanced computing in statistics and has since become the standard for statistical analysis in the field, replacing commerical packages like SAS and SPSS for the most part. Learning R is an essential part of becoming a scientist who is able to work at the cutting edge of statistical analysis – or even to perform conventional statistical tests (e.g. a t-test) in a standard way. An important part of R is that it is script-based, which makes it easy to create reproducible analysis pipelines, which is an emerging feature of the open data/open analysis movement in science. This is becoming an important component of publication and sharing of research results, so being able to engage fully with this effort is something that all young scientists should do. RMarkdown is an extra layer placed on top of R that makes it easy to integrate text explanations of what is going on, native R code/scripts, and R output all in one document. The final result can be put into a variety of forms, including webpages, pdf documents, Word documents, etc. Entire books are now written in RMarkdown and its relatives. It is a great way to make quick webpages, like this document, for instance. It is very easy to use and will be the format that I use to distribute your assignments to you and that you will use to turn in your assignments. R Projects are a simple way of designating a working directory in which to house files related to a given, well, project. Those files might include primary data and metadata files ready for reading into R, .R scripts, Rmarkdown files, and output such as Rmarkdown-rendered .html files or individual plots, for example. The nice thing about organizing your work with R Projects is that you can keep everthing needed to reproduce an analysis in a single directory on your computer. You can open an R Project in RStudio by opening the project’s index (.RProj) file, which will automatically set your working directory to that of the project and facilitate loading any saved environments, etc. In Chapter 6 we will begin working in R and RStudio, but you can get them installed now (in that order) on your computer, if you haven’t already. Get the most recent released R version by following this link: https://www.r-project.org/ We will do our work using Rstudio, which is a powerful and convenient user interface for R, and can be downloaded from here for installation: https://rstudio.com/products/rstudio/ 4.3.1 Learning resources There are tons of resources for learning R and RMarkdown on the internet. Here are just a few, but you will no doubt find your own favorites as you become routine R users. There is an organized group that is dedicated to training in R called DataCamp (https://www.datacamp.com/). They provide all of the basics for free. They actually have training for most data science platforms. RStudio provides links for training directly related to R and RMarkdown here: https://www.rstudio.com/online-learning/ There are also many, many R training videos on YouTube. Most of them are very well meaning but may not be as in-depth as you want. You can also go the old “paper” manual route by reading the materials provided by R itself: https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf In reality, if you want to do almost anything in R, simply type in what you are interested in doing into Google and include “in R” and a whole bunch of links telling you exactly what to do will magically appear. Most of them appear as discussions on websites like StackOverflow and Stats.StackExchange. In that case, the first thing that you see is the question–usually someone doing it just a bit wrong–so you should scroll down to see the right way to do it in the answers. It is really an amazing resource that will speed you along in nearly every form of analysis that you are interested in. Please do not hesitate to contact us if you have questions or run into obstacles. The point of this class is to learn by doing, but our aim is that the doing should involve reasonable first efforts supplemented with help if needed. Also, many of your classmates have some experience with R, writing code, or statistics in general, so they are an excellent resource as well! "],
["organizing-and-manipulating-data-files.html", "Chapter 5 Organizing and manipulating data files 5.1 Introduction 5.2 Navigating file systems from the command line 5.3 Data file and data file entry dos and don’ts 5.4 Exercises associated with this chapter: 5.5 Additional learning resources", " Chapter 5 Organizing and manipulating data files 5.1 Introduction Many of you will already be familiar with data file organizaiton, editing, and formatting for analysis. If so, much of the following material may be review. If not, some of the following guidelines and tools should prove to be quite useful. In biology, and many other fields, primary data are routinely stored as “flat” text files. The exact formatting depends on the type of data, of course, but often we are working with text files organized into rows and columns. Rows can naturally be defined by lines in a file, and columns can be defined by separators (also called delimiters) such as spaces, tabs, or commas, to name a few commonly used ones. Fortunately there are some very powerful and simple-to-use (with a little practice) tools that can be invoked directly from a computer’s command line, or included in written “scripts” that your computer’s operating system can interpret upon you running them. These command line tools are now nearly ubiquitous on all personal computer platforms. Computers running a LINUX operating system allow direct access to these tools via the command line, as does the macOS operating system of Apple computers via the Terminal. Computers running Microsoft Windows 10 now also facilitate use of these conventional “UNIX tools” through a Windows Subsystem for Linux. In the following sections, we provide a very brief introduction to using some of these tools in order to organize your data files, parse them for information, and perform some basic text manipulations. Mastering these activities is not necessary for this course (in fact, many of the text manipulation tasks can be done in R!), but if you learn to adopt at least some of these skills you will become a better, more organized analyst, and it will help you become comfortable with the command line and programming in general. 5.2 Navigating file systems from the command line 5.2.1 Access to the command line The first step to using command line tools is to get access to the command line! On Mac and Linux systems you can simply do this by finding and opening the Terminal application. On Windows 10 systems, you’ll have to install a Linux Bash Shell if you haven’t already. To do this you will need to follow the instructions here: https://itsfoss.com/install-bash-on-windows/ When you get to the point of choosing the Linux distribution to install, I recommend Ubuntu. At this point you should have command line access through a terminal prompt, which should look something like my Mac Terminal below: You are now ready to navigate and explore files simply by typing! 5.2.2 Navigating directories and files When you are at the command line, just think of your computer as you would if you were navigating using a graphical application (e.g. Mac Finder or Windows Explorer). You are always in a directory in your file system, and you can move to any other directory by typing the approriate command and destination, then hitting Enter. The first crucial UNIX command to learn is pwd. This command stands for “print working directory,” and it will literally print the path of the directory you are currently in. Another important command is ls. This lists the files and directories (by default) in your working directory. If you specify a different directory, it will list the files and/or directories there. Most UNIX commands (and indeed command-line programs in general), can be run with options. One way to invoke the and option is to type a “flag” along with the command. In the case of ls, we can type ls -l, for example, which will print the output line-by-line. We can also add annother flag: ls -lh (equivalent to ls -l -h), which will print items line-by-line but also make sure the item sizes are “human readable.” If you ever have quesitons about how to use UNIX program, including the flags and other options, you can type man program_name and a wonderful help manual will appear. To exit and return to the command prompt, just hit “q”. These man pages are extremely useful and should be your first go-to if you need information for a particular command. Please use these regularly! The command cd will change your location from the current directory to another directory. Like many other programs (UNIX and otherwise) require you to input directory and file locations, with cd you can specify your desired location using either the absolute or relative path. An absolute path is the full “address” of a directory or file, starting from the root of your file system. An example of an absolute path to a directory in my file system is /Users/csmall/Dropbox/sculpin_project/images/. Regardless of where my current working directory is in my file system, I can change to this images/ directory using cd and the full path. I can also use a relative path, which is a sort of “shortcut,” to specify the location of a directory or file. Let’s say I am in /Users/csmall/Dropbox/BiostatsFound_S2020/ and I want to get to the images/ directory above. I could type cd ../sculpin_project/images, which uses a relative path to take me “up” one directory (as denoted by ../) into Dropbox/ and back “down” into sculpin_project/images. In fact, .. is a special file in every directory that just means “the directory above.” The special file . is the current directory. And to mention one final useful designation for navigation shortcuts, you can use the ~ to denote your home directory. The schematic below should help you visualize how to think about file system navigation from the commmand line: And for another example, take a look at this series of navigation commands from my terminal and see if you can follow along: If you want to create a new directory, you can use the mkdir command, including the desired name of the new directory. By default this will create the directory in your current working directory, but you can use absolute or relative paths to instead write the directory somewhere else. If you want to delete an empty directory, rmdir is the appropriate command. Now let’s briefly cover some UNIX commands that are useful for managing files. Some of these apply to directories as well, which I will point out as we go. The command touch can be used to create a new, empty file, which you can add to using a plain text editor. Examples of popular plain text editors with advanced user interfaces are BBEdit and Atom. You can also use command line text editors, such as nano, emacs, and vim. Most UNIX/LINUX systems have nano installed by default. To copy or change the name and/or location of a file (or directory), use cp and mv commands, respectively. Note that by using absolute or relative paths, you can specify where you want the file or directory to end up. Be especially careful with these, however, because you will overwrite any existing file or directory if you specify the same name and location. Another command you should be extremely cautious with is rm, which removes (permanently deletes) a file. rm -r can be used to delete a non-empty directory AND all of its contents. In many cases you will want to look at files, or parts of them at least, from the command line. cat will print the entire contents of a file, but can also be used to combine (“concatenate”) multiple files in a line-wise manner. less and more will display specific lines of a file (starting with the first ones), with single- or multi-line “scrolling,” respectively, activated using the return or down-arrow keys. To leave the display, you need to hit the “q” key. head and tail will display the first or last, respectively, n lines of the file, where n is provided as a flag (e.g. head -200 file.tsv). The “word count” command wc can quantify elements of a text file in various ways, but one common application is wc -l, which counts the number of lines in a file. An aside: If you are working from the command line and want to terminate a process (say you accidentally start a task that will take way too long), press Ctrl-C. 5.2.2.1 A quick review of important UNIX commands for navigation and viewing pwd - prints working directory ls - lists contents of a directory cd - changes the working directory mkdir - creates a new directory rmdir - deletes an empty directory touch - creates an empty file cp - copies a file or directory mv - changes the name of a file or directory rm - deletes a file, or a directory and everyting inside with -r cat - prints the entire file to the terminal, or concatenates and prints multiple files less - displays the first lines of a file, with scrolling line-by-line head - prints the first 10 lines (default) of a file tail - prints the last 10 lines (default) of a file wc -l - prints the number of lines in a file 5.2.3 Useful UNIX commands for file manipulation In many cases you will want to search for specific characters or combinations of characters, and do various things with that information. Maybe you want to isolate the lines of a file that contain the query, or perhaps you want to count how many lines contain the query. The tool grep is extremely useful in this regard. We don’t have time for a comprehensive dive into the utilities of grep, but a few common applications are worth mentioning. Character patterns we search for using grep may or may not involve special characters that are not interpretted literally. Here we will discuss just a few common cases of grep searches and the special characters involved. Some examples of these special characters include ^ (beginning of a line), $ (end of a line), . (any single character except a newline), * (zero or more instances of the preceeding character), and \\s (any white space). The standard syntax for grep from the command line is grep &quot;expression&quot; filename. So, if you wanted to return all of the lines in the data file zfish_data.tsv (assuming it is in the current directory) that begin with “embryo_10”, you could try grep &quot;^embryo_10&quot; zfish_data.tsv. This search would also (unintentionally) find lines beginning with “embryo_100” or “embryo_101”, etc., if they exist. So, you have to be careful, and learning the rules just takes practice. In this case grep &quot;^embryo_10\\s&quot; zfish_data.tsv would acheive the desired result, assuming that there is a whitespace delimiter between fields (“columns”) in the data file. Useful flags for grep include -c (which counts the number of lines containing the query), -v (which returns the lines that do not contain the query), and -n (which prints the line number for each line containing the query). I encourage you to look at many different grep use cases online as your demand for complex searches grows. The program sed has reasonably complex applciations, but is commonly used as a sort of “search and replace” tool. The syntax for sed use is similar to grep, except that the query and replacement expressions are organized (with other information) using slashes. For “search and replace” functionality, that sytax looks like this: sed 's/query/replacement/flag' filename. One common option for the “flag” component is “g”, meaning “global”, which replaces all instances. If no flag designation is made only the first instance in the file is replaced. Building on our toy example from above, sed 's/^embryo_/^larva_/g' zfish_data.tsv would perform a global replacement and print the output to the terminal. To change the contents in the original file on the fly, including sed -i would do the trick, but is riskier than redirecting the output to a new file. cut is quite straightforward, and can be used to isolate individual fields (think of them like “columns”) from a text file, provided the fields are consistently separated by a delimeter on each line. So, if I had a comma-separated file and I just wanted the first two columns I could type cut -f1,2 -d&quot;\\t&quot; filename. Note that if you don’t specify a delimter using the -d flag, then it is assumed to be tab-delimited. If you want to bring together fields in separate files, join can be used to accomplish this. The two files should have equivalent rows, however, for this action to work properly. If you want to sort text files alphanumerically, in a field-wise fashion, sort is quite useful. If a file contains a single field, minimal specification is required, aside from tuning numerical sorting. For example, if you want to sort numerically, use the -n flag, and if you want to sort from largest to smallest, add the -r flag. If you want to sort a multi-field file based on just one field, you can use the “key” flag. For instance, if you have a tab-delimited file and want to sort by the second field in reverse numerical order, sort -k2,2 -nr filename.tsv would give you the desired result. Finally, if you want to eliminate lines with the same value for a given field, you can use the -u “unique” flag. The UNIX program awk is an extremely powerful tool, and can itself be used essentially as a mini programming language. We will not get into the myriad uses of awk here, but the reference at the bottom of the chapter is a great resource if you want to learn more. awk is extremely efficient at parsing and capturing text files in a column-wise manner, with the ability to also evaluate logical statements applied to rows. The structure of awk commands is more complex than that of other UNIX programs we have discussed, but it is still very intuitive. One unique feature is that awk contains its own internal functions, which are typed inside curly braces. The “print” function can be used to extract fields, much like cut. For instance, awk -F: '{print $1,$6}' filename.tsv would print the first and sixth field from filename.tsv, assuming a “:” delimiter. With awk, fields are specified using the $ character. If you want also to select only specific rows from a set of columns (like those with a certain value), you can incorporate logical operators. In the above example if we had wanted fields 1 and 6, but only those rows with a value of at least 610 in field 2, we could type the following awk -F: '$4 &gt;= 610 {print $1,$6}' filename.tsv. Again, this is just scratching the surface with awk, which boasts a great deal of potential for your text file manipulation needs. 5.2.3.1 A quick review of key UNIX commands for text file searching and manipulation grep - searches a file for characters and character combinations sed - stream edits characters and character combinations cut - isolates specific fields (“columns”) from a file using a delimiter join - combines fields (“columns”) from multiple files with equivalent rows sort - orders the rows in a file based on one or more fields awk - flexibly parses, evaluates, and selectively prints row- and column-wise 5.2.4 A quick word on pipes and carrots One very convenient feature of UNIX commands is that you can control the flow of input and output from one command to another using the | (“pipe”) character. For instance, I may want to search an entire file for rows that begin with “fish-1”, and then replace the “-” with &quot;_“. To do this I could do something like cat file.tsv | grep &quot;^fish-1&quot; | sed 's/fish-1/fish_1/g' This, of course, would print the output to the terminal, but I could actually capture that output into a file using the &gt; charcter. cat filename | grep &quot;^fish-1&quot; | sed 's/fish-1/fish_1/g' &gt; ./newfile.tsv would write this new file to my current working directory. Furthermore, if you want to append lines of text to an existing file, the”double sideways right-pointing carrot&quot; character &gt;&gt; can be used. The above lessons on UNIX commands for file manipulation truly just scratch the surface of what can be accomplished at the command line and in “shell scripts.” You certainly will have further questions and be hungry for more, but we simply don’t have time during this course. But to work on your UNIX skills for now, check out Ex1_Unix_Intro.html (on Canvas). We need to move on to R now, but at the bottom of this chapter are some UNIX command resources I have found to be especially useful. 5.3 Data file and data file entry dos and don’ts Do store a copy of your data in a nonproprietary format, such as plain ASCII text (aka a flat file). This is especially important if you are using tools (like UNIX commands) to parse and manipulate the files. Formats like Microsoft Excel are not acceptable as input for many analysis tools, and not everyone has access to proprietary software. Do leave an un-edited copy of an original data file, even when main analyes require an edited version. Do use descriptive names for your data files and variables, and use them consistently! Do maintain effective metadata about the data. Do add new observations to a data file as rows. Do add new variables to a data file as columns. Don’t include multiple data types in the same column. Don’t use non-alphanumeric characters (other than the underscore) in file or directory names. Don’t use spaces, tabs, commas, colons, semicolons, or other chacters commonly used as field (column) delimiters in names of individual data entries. For example, don’t use something like March 8 as a value for date in a data set. Don’t copy and paste data directly from rich-text-formatted files (like Microsoft Word) into primary data files. 5.4 Exercises associated with this chapter: Exercise 1 (file: Ex1_Unix_Intro.html) 5.5 Additional learning resources http://mally.stanford.edu/~sr/computing/basic-unix.html - A nice “cheat sheet” http://korflab.ucdavis.edu/Unix_and_Perl/ - Outstanding tutorial by Keith Bradnam and Ian Korf https://www.datacamp.com/courses/introduction-to-shell-for-data-science - DataCamp tutorial https://www.gnu.org/software/gawk/manual/gawk.html - A comprehensive guide to awk "],
["an-introduction-to-the-r-language.html", "Chapter 6 An Introduction to the R language 6.1 Background 6.2 Why use R? 6.3 Important R terms and definitions 6.4 Getting started with R via the RStudio Environment 6.5 Exercises associated with this chapter: 6.6 Additional learning resources:", " Chapter 6 An Introduction to the R language 6.1 Background R is a computer programming language and environment especially useful for graphic visualization and statistical analysis of data. It is an offshoot of a language developed in 1976 at Bell Laboratories called S. R is an interpreted language, meaning that every time code is run it must be translated to machine language by the R interpreter, as opposed to being compiled prior to running. R is the premier computational platform for statistical analysis thanks to its GNU open-source status and countless packages contributed by diverse members of the scientific community. 6.2 Why use R? Good general scripting tool for statistics and mathematics Powerful and flexible and free Runs on all computer platforms New packages released all the time Superb data management &amp; graphics capabilities Reproducibility - can keep your scripts to see exactly what was done Can embed your R analyses in dynamic, polished files using R markdown You can write your own functions Lots of online help available Can use a nice IDE such as RStudio 6.3 Important R terms and definitions Alt text From Logan, M. 2010. Biostatistical Design and Analysis Using R Operators are symbols in programming that have a specific meaning Alt text From Logan, M. 2010. Biostatistical Design and Analysis Using R 6.4 Getting started with R via the RStudio Environment To begin working with R, open RStudio. You should first see something that looks like this: To open a new script editor (where you will keep track of your code and notes), go to File &gt; New File &gt; R Script. Note that there are other options for file types, which we will be using in the future. For now, though, we want a plain script, which when saved will have the extention .R. It is easy to run code directly from the script editor. For single lines of code, simply make sure your cursor is on that line, and hit Ctrl-Enter. For multiple lines, highlight the block of code you want to run and hit Ctrl-Enter. Now your display should look somehting like below (but without the red pane labels, of course): Note that you can also type commands directly from the command line using the R Console (lower left pane), and the R interpreter will run them when you press Enter. Any objects you define, and a summary of their values, will appear in the upper right pane, and the lower right pane differs in appearance depending on instructions you provide to R Studio. For instance, if you produce a plot, it will appear there by default. Another extremely important feature of R functions (we’ll get to them in a bit) is the help file. Recall from Chapter 5 our discussion of man pages for UNIX programs. Help files the equivalent for R functions. They contain almost everything you need to know about a given function, and most of them even include and example at the bottom. These help files will appear in the lower right RStudio pane when you call them, for example when you run help(function_name) at the R Console. 6.4.1 R Programming Basics For the code examples below, it might be useful for you to start your own RStudio session, open a new .R file and type/run code while reading. Commands can be submitted through the terminal, console or scripts In your scripts, anything that follows # symbol (aka hash) is just for humans Notice on these slides I’m evaluating the code chunks and showing output The output is shown here after the two # symbols and the number of output items is in [] Also notice that R follows the normal priority of mathematical evaluation 4*4 ## [1] 16 (4+3*2^2) ## [1] 16 6.4.1.1 A note on R Markdown This format provides a much better way to embed code and output, in an easily readable, reproducible manner. We will dive into R Markdown next week, so for now just be aware that it exists. http://kbroman.org/knitr_knutshell/pages/Rmarkdown.html You can insert R chunks into Rmarkdown documents 6.4.1.2 Assigning Variables To “store” information for later use, like the arithmetic operation above, we can assign variables in R. Variables are assigned values using the &lt;- operator. Variable names must begin with a letter, and should not contain spaces or R operators (see above) but other than that, just about anything goes. Do keep in mind that R is case sensitive. x &lt;- 2 x * 3 ## [1] 6 y &lt;- x * 3 y - 2 ## [1] 4 These do not work 3y &lt;- 3 3*y &lt;- 3 6.4.1.3 Arithmetic operations with functions Arithmetic operations can be used with functions as well as numbers. Try the following, and then your own. x+2 x^2 log(x) + log(x+1) Note that the last of these - log() - is a built in function of R, and therefore the argument for the function (in this case “x” or “x+1”) needs to be put in parentheses. These parentheses will be important, and we’ll come back to them later when we add other arguments after the object in the parentheses. The outcome of calculations can be assigned to new variables as well, and the results can be checked using the print() function. y &lt;- 67 print(y) ## [1] 67 x &lt;- 124 z &lt;- (x*y)^2 print(z) ## [1] 69022864 6.4.1.4 Strings Assignments and operations can be performed on characters as well. Note that characters need to be set off by quotation marks to differentiate them from numeric objects. The c(function) stands for ‘concatenate’. Note that we are using the same variable names as we did previously, which means that we’re overwriting our previous assignment. A good general rule is to use new names for each variable, and make them short but still descriptive x &lt;- &quot;I Love&quot; print (x) ## [1] &quot;I Love&quot; y &lt;- &quot;Biostatistics&quot; print (y) ## [1] &quot;Biostatistics&quot; z &lt;- c(x,y) print (z) ## [1] &quot;I Love&quot; &quot;Biostatistics&quot; The variable z is now a vector of character objects. 6.4.1.5 Factors Sometimes we would like to treat character objects as if they were units for subsequent calculations. These are called factors, and we can redefine our character object as one of class factor. This might seem a bit strange, but it’s important for statistical analyses where we might want to calculate the mean or variance for two different treatments. In that case the two different treatments would be coded as two different “levels” of a factor we designate in our metadata. This will become clear when we get into hypothesis testing in R. z_factor &lt;- as.factor(z) print(z_factor) class(z_factor) Note that factor levels are reported alphabetically. I used the class() function to ask R what type of object “z_factor” is. class() is one of the most important tools at your disposal. Often times you can debug your code simply by changing the class of an object. Because functions are written to work with specific classes, changing the class of a given object is crucial in many cases. 6.4.1.6 Vectors In general R thinks in terms of vectors (a list of characters factors or numerical values) and it will benefit any R user to try to write programs with that in mind. R operations, and therefore functions, are vectorized. This means an operation or function will be performed for each element in a vector. Vectors can be assigned directly using the ‘c()’ function and then entering the exact values. x &lt;- c(2,3,4,2,1,2,4,5,10,8,9) print(x) ## [1] 2 3 4 2 1 2 4 5 10 8 9 x_plus &lt;- x+1 print(x_plus) ## [1] 3 4 5 3 2 3 5 6 11 9 10 Creating vectors of new data by entering it by hand can be a drag. However, it is also very easy to use functions such as seq() and sample(). Try the examples below. Can you figure out what the three arguments in the parentheses mean? Within reason, try varying the arguments to see what happens seq_1 &lt;- seq(0.0, 10.0, by = 0.1) print(seq_1) ## [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 ## [16] 1.5 1.6 1.7 1.8 1.9 2.0 2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 ## [31] 3.0 3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 4.0 4.1 4.2 4.3 4.4 ## [46] 4.5 4.6 4.7 4.8 4.9 5.0 5.1 5.2 5.3 5.4 5.5 5.6 5.7 5.8 5.9 ## [61] 6.0 6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 7.0 7.1 7.2 7.3 7.4 ## [76] 7.5 7.6 7.7 7.8 7.9 8.0 8.1 8.2 8.3 8.4 8.5 8.6 8.7 8.8 8.9 ## [91] 9.0 9.1 9.2 9.3 9.4 9.5 9.6 9.7 9.8 9.9 10.0 seq_2 &lt;- seq(10.0, 0.0, by = -0.1) print(seq_2) ## [1] 10.0 9.9 9.8 9.7 9.6 9.5 9.4 9.3 9.2 9.1 9.0 8.9 8.8 8.7 8.6 ## [16] 8.5 8.4 8.3 8.2 8.1 8.0 7.9 7.8 7.7 7.6 7.5 7.4 7.3 7.2 7.1 ## [31] 7.0 6.9 6.8 6.7 6.6 6.5 6.4 6.3 6.2 6.1 6.0 5.9 5.8 5.7 5.6 ## [46] 5.5 5.4 5.3 5.2 5.1 5.0 4.9 4.8 4.7 4.6 4.5 4.4 4.3 4.2 4.1 ## [61] 4.0 3.9 3.8 3.7 3.6 3.5 3.4 3.3 3.2 3.1 3.0 2.9 2.8 2.7 2.6 ## [76] 2.5 2.4 2.3 2.2 2.1 2.0 1.9 1.8 1.7 1.6 1.5 1.4 1.3 1.2 1.1 ## [91] 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 seq_square &lt;- (seq_2)*(seq_2) print(seq_square) ## [1] 100.00 98.01 96.04 94.09 92.16 90.25 88.36 86.49 84.64 82.81 ## [11] 81.00 79.21 77.44 75.69 73.96 72.25 70.56 68.89 67.24 65.61 ## [21] 64.00 62.41 60.84 59.29 57.76 56.25 54.76 53.29 51.84 50.41 ## [31] 49.00 47.61 46.24 44.89 43.56 42.25 40.96 39.69 38.44 37.21 ## [41] 36.00 34.81 33.64 32.49 31.36 30.25 29.16 28.09 27.04 26.01 ## [51] 25.00 24.01 23.04 22.09 21.16 20.25 19.36 18.49 17.64 16.81 ## [61] 16.00 15.21 14.44 13.69 12.96 12.25 11.56 10.89 10.24 9.61 ## [71] 9.00 8.41 7.84 7.29 6.76 6.25 5.76 5.29 4.84 4.41 ## [81] 4.00 3.61 3.24 2.89 2.56 2.25 1.96 1.69 1.44 1.21 ## [91] 1.00 0.81 0.64 0.49 0.36 0.25 0.16 0.09 0.04 0.01 ## [101] 0.00 seq_square_new &lt;- (seq_2)^2 print(seq_square_new) ## [1] 100.00 98.01 96.04 94.09 92.16 90.25 88.36 86.49 84.64 82.81 ## [11] 81.00 79.21 77.44 75.69 73.96 72.25 70.56 68.89 67.24 65.61 ## [21] 64.00 62.41 60.84 59.29 57.76 56.25 54.76 53.29 51.84 50.41 ## [31] 49.00 47.61 46.24 44.89 43.56 42.25 40.96 39.69 38.44 37.21 ## [41] 36.00 34.81 33.64 32.49 31.36 30.25 29.16 28.09 27.04 26.01 ## [51] 25.00 24.01 23.04 22.09 21.16 20.25 19.36 18.49 17.64 16.81 ## [61] 16.00 15.21 14.44 13.69 12.96 12.25 11.56 10.89 10.24 9.61 ## [71] 9.00 8.41 7.84 7.29 6.76 6.25 5.76 5.29 4.84 4.41 ## [81] 4.00 3.61 3.24 2.89 2.56 2.25 1.96 1.69 1.44 1.21 ## [91] 1.00 0.81 0.64 0.49 0.36 0.25 0.16 0.09 0.04 0.01 ## [101] 0.00 Here is a way to create your own data sets that are random samples. Again, on your own, play around with the arguments in the parentheses to see what happens. x &lt;- rnorm (10000, 0, 10) y &lt;- sample (1:10000, 10000, replace = T) xy &lt;- cbind(x,y) plot(x,y) You’ve probably figured out that “y” from the last example is a draw of numbers with equal probability (what we call a flat, or uniform distribution). What if you want to draw from a distribution? Again, play around with the arguments in the parentheses to see what happens. x &lt;-rnorm(1000, 0, 100) print (x) ## [1] 103.9324868 -11.1956524 -71.7256940 -67.1839786 67.2928553 ## [6] -67.4238963 19.6146342 -151.1225404 -96.1124192 207.4859938 ## [11] -63.7470866 85.1368105 -56.5212064 66.9409935 -6.6250966 ## [16] 256.0711639 75.5165203 21.5175311 -157.8591253 -154.6798677 ## [21] -119.7751774 132.8903266 -22.8873496 -156.7465971 -63.7389674 ## [26] -23.9281163 -92.7798254 -6.7063641 -84.0717520 -125.9195626 ## [31] 1.9301845 -122.5967509 -43.3179965 6.0029870 -23.0235214 ## [36] 153.0078161 -90.7988087 -134.8595262 -17.7698291 -110.6119714 ## [41] 122.6673213 71.9504047 68.0382297 15.3869320 220.1629730 ## [46] -62.5342600 40.7467219 87.5090923 -197.5445725 -56.7731212 ## [51] 6.4339420 41.6161557 -155.1842640 -147.7983967 75.3086501 ## [56] -65.2329385 24.1753091 -70.2911252 114.9842073 -19.3055997 ## [61] -38.1809939 50.5264187 65.5017094 187.3234962 78.1859059 ## [66] 202.2138972 79.9305502 127.2054530 -26.5113012 -56.2096654 ## [71] 67.7071185 23.5502098 78.8044798 -51.4588947 133.8888231 ## [76] -284.5357466 -92.7703292 13.6718931 23.3952430 -0.5435480 ## [81] -108.9093764 34.8301191 70.6834841 3.6755661 85.5112722 ## [86] 92.5101622 80.1107647 54.9866484 -328.9480805 -34.5930417 ## [91] -73.6917928 -47.8896076 32.1420160 113.7933059 -95.5965241 ## [96] -140.5311611 247.6383111 11.1171636 167.0353359 10.6606966 ## [101] -98.9383378 179.8118169 -0.1702243 28.6963743 30.1646926 ## [106] -101.9347350 -98.6655932 -111.2297971 48.5612680 -112.8967511 ## [111] -107.4850884 77.9492963 -85.4542377 -128.8704708 190.7395456 ## [116] -12.5911248 58.4984857 14.8314188 -77.7357148 -39.7529340 ## [121] 22.3274833 -39.8739166 -15.9763803 -93.7709971 -206.3490015 ## [126] 223.9824102 55.4000434 -105.3147911 26.3742434 -64.4059801 ## [131] -37.2444574 -140.8164707 -91.4365908 -76.9316614 -38.5642222 ## [136] 114.7880625 -46.4402515 -147.1940997 14.7240385 -19.0961464 ## [141] 93.8262335 -48.6363739 -220.2140530 256.0162300 113.9533792 ## [146] -97.0430727 30.6668543 149.6775971 -151.2015245 73.7338080 ## [151] 164.7683422 -149.9676751 137.9712055 -26.1748520 75.7613130 ## [156] -76.3621245 -147.9282753 12.0929862 82.9398475 -91.1949259 ## [161] -17.1472328 222.8048700 -3.5522213 -41.3417727 30.6571277 ## [166] -38.8183459 32.4218424 102.1335046 -7.9665228 151.7299599 ## [171] 32.6726376 -55.9040000 -9.5377664 -67.7862501 -91.1669812 ## [176] 91.9538877 141.2739946 -68.6741875 -12.3126504 -100.7675078 ## [181] -57.1387501 100.2100710 -40.2977584 -32.5938751 -88.5188102 ## [186] 56.7582971 -81.7895505 -24.8629734 97.6838010 -45.2806465 ## [191] -147.7679552 -63.1459174 -119.7258613 13.8477570 109.8930013 ## [196] 84.9301768 -7.5566192 55.7978643 112.4624037 -62.0657834 ## [201] 5.5449710 111.1396392 91.6685656 -10.9367275 68.7577840 ## [206] 32.8059079 -62.6332812 -217.5002728 -53.0072431 -62.9872741 ## [211] -98.6267092 29.3768741 -120.0512119 -23.6395751 -159.2465731 ## [216] -108.8389732 -49.2977691 49.9291190 58.2468170 -73.5493895 ## [221] -89.6919952 261.4904820 -39.5644291 -23.7039916 56.4057833 ## [226] 142.2133654 -6.3109226 -129.1535830 44.2590368 69.8892694 ## [231] -102.0680504 1.3797979 39.6415595 -142.7891383 142.9425956 ## [236] 130.5979757 -131.0006280 32.1388871 -142.2966118 -76.5060847 ## [241] 204.9130510 203.7104208 -152.8645883 58.8890574 70.9355634 ## [246] 23.7074959 -105.3253049 -102.8417137 -38.1740205 -107.6489132 ## [251] 143.1066106 55.2486401 139.8385977 -34.7756658 -205.1949189 ## [256] -39.2515296 -39.5365414 -35.7157458 13.1779472 -9.9892326 ## [261] 83.3604898 -69.5289007 73.9755200 -10.9924352 17.2114987 ## [266] 30.8488757 -146.5025183 128.4188274 32.4339491 33.4092950 ## [271] -67.6446832 -226.0239773 -134.8969194 -100.6193292 8.8590853 ## [276] 60.8545931 12.0537744 -159.4263941 -87.2243432 6.4863330 ## [281] -155.5646772 -46.8643163 69.2629290 -14.7625051 19.9192268 ## [286] -66.4757138 65.0958172 -45.3518745 -22.7858977 31.1493246 ## [291] 10.1650284 -128.3090099 176.5933676 -66.7359437 -109.8424148 ## [296] -14.2064997 29.1245476 -126.7013073 -18.7674701 65.5986835 ## [301] -27.3125764 73.4609923 36.6374153 269.2391673 14.6810951 ## [306] 6.3504738 133.6240124 106.0778894 -85.4663430 -75.7861866 ## [311] -133.7075233 51.8243510 42.9698819 -43.3536798 -195.1758099 ## [316] -3.7523330 -103.9097443 152.5828652 -137.9490788 -78.2696184 ## [321] -81.5562471 30.8432464 28.6707579 -41.7401717 -39.8596575 ## [326] -27.2830487 -21.3236487 86.9341349 -77.6900016 15.7716676 ## [331] 94.3121836 -21.6539542 15.2387189 47.5761701 109.2723461 ## [336] 112.3825397 51.1138173 -53.2456279 2.0376677 3.1220990 ## [341] -12.6301384 -82.2359187 82.0475472 131.2056972 -42.8007793 ## [346] 66.9516067 55.8348443 23.6430475 -39.4850720 -156.3170414 ## [351] -85.1074664 -31.0501833 -149.6059776 107.7039439 50.5392768 ## [356] -27.6098998 -194.4382282 -54.7854288 -87.3767382 -172.3210013 ## [361] 153.0019963 57.1315765 -40.3011103 -15.0565855 -114.7634718 ## [366] -15.8710899 124.7588052 -101.9963725 103.2612833 18.3519456 ## [371] -133.2833477 2.0436922 -149.3671831 -0.6069020 -52.7633258 ## [376] 71.9634097 187.3293758 -168.9823775 68.1910598 -52.2070942 ## [381] -227.0333771 -127.0365069 186.6888451 24.2596710 -63.1003321 ## [386] -126.4140358 -74.9348060 38.4661135 -92.5390068 -35.3294340 ## [391] 68.6981040 42.6607735 152.9597126 -146.3531330 -93.8052117 ## [396] 5.7887636 -134.7039789 47.9559993 31.8331106 -38.3543855 ## [401] 14.0966784 46.2575443 141.4878993 -95.3252032 81.2918383 ## [406] 34.5881301 38.6109636 185.0410230 0.8759658 -124.4190709 ## [411] 19.7725786 44.6276130 28.7919725 -5.5837292 31.5424928 ## [416] 170.9266493 38.2955845 -76.5024966 108.7345512 -81.8922252 ## [421] 118.9371326 52.3045354 -138.7158431 17.6929442 -40.8194694 ## [426] 132.7499578 -155.5214075 84.9854266 -14.8078120 50.8421163 ## [431] 117.7142213 277.0816263 162.0268308 -74.3479789 -48.9282524 ## [436] -36.0915032 -254.1905874 1.5618846 135.5708984 110.6455105 ## [441] -22.6220890 91.1941070 154.3079091 189.0553630 79.5822392 ## [446] 27.8742527 42.2250940 -9.6393094 64.2453071 -102.6334432 ## [451] -9.5106724 70.3179869 156.9262742 28.0872063 -9.5220867 ## [456] -156.4179798 -93.3007117 32.8648817 -33.2957701 83.0872898 ## [461] 44.1566199 136.8921330 -69.1916541 114.7345528 -77.5911488 ## [466] 102.7557283 66.0895266 -45.2858181 22.5656136 28.0467464 ## [471] 102.0714412 -45.0158524 57.0071700 -32.3694797 -162.3992463 ## [476] -129.2962655 -64.0932270 -12.6574591 -155.4083509 -3.7023697 ## [481] -49.2511467 -99.2752325 108.0795854 -137.8212406 5.5924877 ## [486] -59.7790713 133.0595189 104.0551815 -37.9856152 20.3674975 ## [491] 78.2489056 155.0622222 -39.6003032 104.7180570 92.9802101 ## [496] -62.5488097 -3.7651658 -111.8750488 -37.5513439 -30.3200411 ## [501] -37.9130624 97.4957078 -32.7186369 -12.4925821 -120.7277708 ## [506] 16.5130743 60.8180548 -186.8039900 84.0543241 -52.4068761 ## [511] 44.5220151 -95.0108833 -61.1660606 94.5657142 -123.4540838 ## [516] -116.3918982 186.5674630 -6.7013211 22.7590260 97.1352470 ## [521] 31.5539686 -31.0653508 144.8651690 53.1427513 -69.5741529 ## [526] 137.4894492 86.6817440 187.4030904 -43.1044180 98.6468261 ## [531] -61.3993022 75.2471849 -35.9559378 -44.5132318 51.6697831 ## [536] -61.9401084 107.3145530 13.2177856 51.6551496 13.4273342 ## [541] -279.1236103 -62.4141605 83.2306277 54.6657823 49.3522965 ## [546] -122.9527299 -21.6114851 -79.2854313 78.0813961 109.4222771 ## [551] -52.6213610 -138.3227178 -88.5043824 58.2956092 56.7354906 ## [556] 38.6057892 -17.4872676 -31.8935230 2.1489772 8.6808802 ## [561] -149.5278490 -185.8075438 -94.4235343 27.1125280 74.6371354 ## [566] -55.3135631 -147.8083508 45.6557932 133.6408834 -52.9263313 ## [571] -78.4240976 -3.6253279 113.5693410 96.2328473 -87.6155496 ## [576] 114.7639497 -92.9769410 -46.8525529 -15.0110534 -55.4909051 ## [581] -73.2253563 -149.1627618 76.3118880 86.4561458 -206.7210885 ## [586] 1.3329008 -17.8027680 134.6806232 -107.4924617 8.8641460 ## [591] 138.1831550 33.7069534 -7.8347785 82.8808781 -36.0541975 ## [596] -106.7551346 -77.3229313 -99.9539817 24.2680908 26.1515102 ## [601] 48.8572134 13.3182754 -104.5362355 -43.0347564 -26.9333828 ## [606] -18.2797032 -196.8653739 38.3359188 3.3175348 181.6175609 ## [611] 86.8867282 -44.1560136 40.1709827 -9.8094805 -213.0689696 ## [616] -12.0101251 102.0977908 32.0045707 92.4536019 55.6092793 ## [621] -196.0472477 -77.6011230 -10.2445423 -28.4870120 -216.2633824 ## [626] 47.3984628 -188.4361770 -76.1218671 146.5166212 -25.8812161 ## [631] -24.4588182 9.8354419 -98.9018656 139.9465134 51.0994306 ## [636] -85.2733249 -88.5536669 223.2444954 -169.0023965 79.6531692 ## [641] -116.4096623 -43.2912182 -23.2963890 29.5487756 -29.9691643 ## [646] -188.9051787 78.8257510 79.0928615 83.3921060 -272.8254585 ## [651] -71.8779516 164.2874672 -14.4222703 -70.5695444 -103.5455485 ## [656] -114.2772317 45.9713700 -89.2569969 56.1874180 17.0355992 ## [661] 4.7248700 37.7063791 -169.6711467 60.0083177 -83.6537325 ## [666] -103.4340405 -50.5161554 84.3099348 -25.9098232 -49.9193730 ## [671] 2.8377693 -26.3241648 16.8747700 10.0808145 -18.1988529 ## [676] 11.1029539 -41.5291015 81.4723928 -111.9920656 -110.7481352 ## [681] -56.2800839 -9.5086257 96.5571963 -13.9148714 -155.9891665 ## [686] -124.7796986 22.8694976 154.8378471 21.1805964 57.8054647 ## [691] 160.7879693 -24.1997679 -120.7125185 -153.1970256 -47.7229802 ## [696] 164.6416038 96.3816274 54.1955599 14.4928742 198.5532006 ## [701] 19.9472463 -51.1545836 -236.0736928 125.5409527 -9.1752384 ## [706] 194.8371336 -142.7868634 -120.5786530 -60.9161767 10.3292264 ## [711] -114.5719529 -146.7973217 -165.2857039 -11.2313379 77.3560334 ## [716] -54.1600234 -53.0757493 -56.0194797 92.0618054 39.8219889 ## [721] 19.4782944 -37.7072396 5.6930436 69.8125404 -85.5849155 ## [726] -95.2694389 69.0643320 -100.4373766 -15.3448210 20.1016962 ## [731] 28.5482727 -84.4684807 -46.3035489 -82.9219494 -68.6049064 ## [736] -96.1438128 167.2811116 -115.8473188 179.3197096 53.2277176 ## [741] -26.2219989 29.1626509 -132.1918271 48.1163927 -167.5933861 ## [746] 27.5207571 -76.3791790 -148.3994490 -94.3977866 110.1755134 ## [751] 22.8919851 -64.8898670 45.2691071 -36.6844262 35.5427728 ## [756] -157.3915264 9.7330021 10.5189950 -33.8390449 7.4486249 ## [761] -12.9016060 -145.7423302 68.7050334 -61.6980078 12.9932907 ## [766] -141.2350405 75.2562689 129.5633749 122.1584352 67.6858823 ## [771] 197.0455205 15.3561385 -47.3696723 -145.2221238 27.5060349 ## [776] -14.1741630 -7.2931436 21.9530289 111.2341535 -1.8473607 ## [781] 61.5026280 135.4982572 2.4801101 0.3266205 -244.8428271 ## [786] -55.2313115 -3.9418506 163.8660711 47.4590404 -53.5498486 ## [791] 212.5748771 -144.1419608 27.7395914 -65.6041700 61.6070865 ## [796] 69.3521706 -14.5458072 -20.1628754 6.3396322 137.0160638 ## [801] 50.8966088 112.5055854 31.9323070 -14.2348494 -37.1444969 ## [806] 6.1914575 88.7305919 5.2856598 136.7375866 -20.7477539 ## [811] -81.1551639 29.3618470 -138.0253006 -89.5618583 39.3422373 ## [816] 12.0988778 118.8790968 4.9392337 103.5852957 98.4726173 ## [821] -210.6070807 40.4818827 -207.5292847 105.5865637 242.8538202 ## [826] -95.5856651 17.7768807 40.8293793 44.4672863 -21.3293696 ## [831] -167.5619145 -1.5706452 -174.8460690 -98.3350204 60.4615506 ## [836] 1.1484282 -183.8370499 -64.8272497 -36.0347256 -184.8474331 ## [841] 250.7260315 -74.2209020 11.4489173 -47.9931566 49.0915464 ## [846] 34.8821293 -61.3888555 -37.2608588 280.5444224 -10.6984289 ## [851] 75.3853383 120.3831189 -73.2183697 -55.8070238 9.2416383 ## [856] -148.8590714 -74.6351473 -114.8149072 70.0965828 -5.5865291 ## [861] -96.3061800 -34.4897980 -48.2268071 94.3102071 17.8177028 ## [866] -22.1721387 -66.4579744 -42.1083507 16.1633417 -75.3834418 ## [871] 20.1979535 -203.7247302 9.2256740 73.6336921 -43.4319820 ## [876] 40.5523318 129.4705276 27.3298102 85.0828377 40.1802781 ## [881] -69.2186570 -103.3681139 -151.1395697 23.9688990 -158.0810155 ## [886] 104.4256054 132.9652207 153.7623387 72.5359192 22.0222953 ## [891] 89.7110380 -25.9587306 109.9867739 -17.5940981 -68.3022083 ## [896] -105.1936306 129.3359977 -118.0005138 -131.7908704 55.7695311 ## [901] 40.1976696 223.3949322 -117.5240113 52.2512727 27.7322248 ## [906] 23.3597106 -35.8980947 166.5604973 73.5862984 104.8535369 ## [911] -48.0936133 153.6396023 -84.3535311 150.6873461 84.8331154 ## [916] 51.7970689 63.7685167 -51.8154888 -40.8210814 -127.9395908 ## [921] -19.0557777 22.7021340 76.2099036 178.1064194 -23.5277920 ## [926] -0.8128318 -15.0148720 -23.8665209 12.3425551 28.6074397 ## [931] -77.5755151 161.8550809 1.1105655 -94.7451692 114.2091118 ## [936] 5.6268471 39.3879714 150.8373450 -264.0842331 -177.8533488 ## [941] 16.7076066 51.4397989 100.8616389 47.0985358 -160.0143245 ## [946] -106.4368792 39.1398660 27.0802138 136.5825632 -6.1928486 ## [951] -19.1120142 161.6937653 21.7572913 -245.6194786 -140.9180271 ## [956] 61.5423452 -28.5477443 -32.0920546 -182.7249139 -227.9491707 ## [961] 18.8146429 -51.1321729 12.9384849 -122.1284715 80.4868353 ## [966] 3.7084689 168.4581663 30.0186020 -47.2449444 -136.8213106 ## [971] -10.0959014 -4.7217274 170.5208322 -35.5756470 86.2846052 ## [976] -124.5274113 59.7827600 20.3300969 36.6768000 -106.8087085 ## [981] 69.3236472 109.5400328 199.8868846 -56.0824593 -81.4114337 ## [986] 56.2529642 47.7652794 -87.4194787 -31.7775059 -36.5276033 ## [991] 69.4293101 -25.7088693 -39.1599235 33.3047499 -20.6033157 ## [996] 301.1860175 -67.2405098 -200.6198473 21.9830730 -59.1811295 hist(x, xlim = c(-50,50)) hist(x, xlim = c(-500,500)) Can you figure out what the three rnorm() arguments represent? 6.4.1.7 Basic Summary Statistics We will get into the details regarding summary statistics later, but for now, check out several of the R functions that calculate them. mean(x) median(x) var(x) log(x) ln(x) sqrt(x) sum(x) length(x) sample(x, replace = T) Notice that the last function (sample) has an argument (replace=T) Arguments simply modify or direct the function in some way There are many arguments for each function, some of which are defaults 6.4.1.8 Getting help to understand functions Getting help on any function is very easy - just type a question mark and the name of the function. There are functions for just about anything within R and it is easy enough to write your own functions if none already exist to do what you want to do. In general, function calls have a simple structure: a function name, a set of parentheses and an optional set of arguments you assign parameters to and send to the function. Help pages exist for all functions that, at a minimum, explain what parameters exist for the function. Help can be accessed a few ways - try them : - help(mean) - ?mean - example(mean) - help.search(&quot;mean&quot;) - apropos(&quot;mean&quot;) - args(mean) 6.5 Exercises associated with this chapter: Exercise 2 (file: rtutorial_1.Rmd) 6.6 Additional learning resources: Logan, M. 2010. Biostatistical Design and Analysis Using R. - A great intro to R for statistical analysis http://library.open.oregonstate.edu/computationalbiology/ - O’Neil, S.T. 2017. A Primer for Computational Biology "],
["references.html", "References", " References "]
]
